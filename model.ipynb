{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make a function for missing values \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pathlib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\machine_learning_project\n",
      "e:\\machine_learning_project\\data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS_SubClass</th>\n",
       "      <th>MS_Zoning</th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot_Shape</th>\n",
       "      <th>Land_Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot_Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc_Feature</th>\n",
       "      <th>Misc_Val</th>\n",
       "      <th>Mo_Sold</th>\n",
       "      <th>Year_Sold</th>\n",
       "      <th>Sale_Type</th>\n",
       "      <th>Sale_Condition</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>141</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "      <td>-93.619754</td>\n",
       "      <td>42.054035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_High_Density</td>\n",
       "      <td>80</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "      <td>-93.619756</td>\n",
       "      <td>42.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>81</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "      <td>-93.619387</td>\n",
       "      <td>42.052659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>93</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "      <td>-93.617320</td>\n",
       "      <td>42.051245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two_Story_1946_and_Newer</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>74</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "      <td>-93.638933</td>\n",
       "      <td>42.060899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MS_SubClass                 MS_Zoning  \\\n",
       "0  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "1  One_Story_1946_and_Newer_All_Styles  Residential_High_Density   \n",
       "2  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "3  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "4             Two_Story_1946_and_Newer   Residential_Low_Density   \n",
       "\n",
       "   Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n",
       "0           141     31770   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "1            80     11622   Pave  No_Alley_Access             Regular   \n",
       "2            81     14267   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "3            93     11160   Pave  No_Alley_Access             Regular   \n",
       "4            74     13830   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "\n",
       "  Land_Contour Utilities Lot_Config  ...            Fence Misc_Feature  \\\n",
       "0          Lvl    AllPub     Corner  ...         No_Fence          NaN   \n",
       "1          Lvl    AllPub     Inside  ...  Minimum_Privacy          NaN   \n",
       "2          Lvl    AllPub     Corner  ...         No_Fence         Gar2   \n",
       "3          Lvl    AllPub     Corner  ...         No_Fence          NaN   \n",
       "4          Lvl    AllPub     Inside  ...  Minimum_Privacy          NaN   \n",
       "\n",
       "  Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition  Sale_Price  Longitude  \\\n",
       "0        0       5      2010       WD          Normal      215000 -93.619754   \n",
       "1        0       6      2010       WD          Normal      105000 -93.619756   \n",
       "2    12500       6      2010       WD          Normal      172000 -93.619387   \n",
       "3        0       4      2010       WD          Normal      244000 -93.617320   \n",
       "4        0       3      2010       WD          Normal      189900 -93.638933   \n",
       "\n",
       "    Latitude  \n",
       "0  42.054035  \n",
       "1  42.053014  \n",
       "2  42.052659  \n",
       "3  42.051245  \n",
       "4  42.060899  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(file_name : str )  -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_folder = pathlib.Path().cwd().parent\n",
    "        print(dir_folder)\n",
    "        file_path  = dir_folder / \"data\" \n",
    "        print(file_path)\n",
    "        df = pd.read_csv(os.path.join(file_path/file_name))\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{file_name}' was not found.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "df = read_file('E:/machine_learning_project/machine_learning_cour2/ames.csv')      \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 74 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   MS_SubClass         2930 non-null   object \n",
      " 1   MS_Zoning           2930 non-null   object \n",
      " 2   Lot_Frontage        2930 non-null   int64  \n",
      " 3   Lot_Area            2930 non-null   int64  \n",
      " 4   Street              2930 non-null   object \n",
      " 5   Alley               2930 non-null   object \n",
      " 6   Lot_Shape           2930 non-null   object \n",
      " 7   Land_Contour        2930 non-null   object \n",
      " 8   Utilities           2930 non-null   object \n",
      " 9   Lot_Config          2930 non-null   object \n",
      " 10  Land_Slope          2930 non-null   object \n",
      " 11  Neighborhood        2930 non-null   object \n",
      " 12  Condition_1         2930 non-null   object \n",
      " 13  Condition_2         2930 non-null   object \n",
      " 14  Bldg_Type           2930 non-null   object \n",
      " 15  House_Style         2930 non-null   object \n",
      " 16  Overall_Cond        2930 non-null   object \n",
      " 17  Year_Built          2930 non-null   int64  \n",
      " 18  Year_Remod_Add      2930 non-null   int64  \n",
      " 19  Roof_Style          2930 non-null   object \n",
      " 20  Roof_Matl           2930 non-null   object \n",
      " 21  Exterior_1st        2930 non-null   object \n",
      " 22  Exterior_2nd        2930 non-null   object \n",
      " 23  Mas_Vnr_Type        1155 non-null   object \n",
      " 24  Mas_Vnr_Area        2930 non-null   int64  \n",
      " 25  Exter_Cond          2930 non-null   object \n",
      " 26  Foundation          2930 non-null   object \n",
      " 27  Bsmt_Cond           2930 non-null   object \n",
      " 28  Bsmt_Exposure       2930 non-null   object \n",
      " 29  BsmtFin_Type_1      2930 non-null   object \n",
      " 30  BsmtFin_SF_1        2930 non-null   int64  \n",
      " 31  BsmtFin_Type_2      2930 non-null   object \n",
      " 32  BsmtFin_SF_2        2930 non-null   int64  \n",
      " 33  Bsmt_Unf_SF         2930 non-null   int64  \n",
      " 34  Total_Bsmt_SF       2930 non-null   int64  \n",
      " 35  Heating             2930 non-null   object \n",
      " 36  Heating_QC          2930 non-null   object \n",
      " 37  Central_Air         2930 non-null   object \n",
      " 38  Electrical          2930 non-null   object \n",
      " 39  First_Flr_SF        2930 non-null   int64  \n",
      " 40  Second_Flr_SF       2930 non-null   int64  \n",
      " 41  Gr_Liv_Area         2930 non-null   int64  \n",
      " 42  Bsmt_Full_Bath      2930 non-null   int64  \n",
      " 43  Bsmt_Half_Bath      2930 non-null   int64  \n",
      " 44  Full_Bath           2930 non-null   int64  \n",
      " 45  Half_Bath           2930 non-null   int64  \n",
      " 46  Bedroom_AbvGr       2930 non-null   int64  \n",
      " 47  Kitchen_AbvGr       2930 non-null   int64  \n",
      " 48  TotRms_AbvGrd       2930 non-null   int64  \n",
      " 49  Functional          2930 non-null   object \n",
      " 50  Fireplaces          2930 non-null   int64  \n",
      " 51  Garage_Type         2930 non-null   object \n",
      " 52  Garage_Finish       2930 non-null   object \n",
      " 53  Garage_Cars         2930 non-null   int64  \n",
      " 54  Garage_Area         2930 non-null   int64  \n",
      " 55  Garage_Cond         2930 non-null   object \n",
      " 56  Paved_Drive         2930 non-null   object \n",
      " 57  Wood_Deck_SF        2930 non-null   int64  \n",
      " 58  Open_Porch_SF       2930 non-null   int64  \n",
      " 59  Enclosed_Porch      2930 non-null   int64  \n",
      " 60  Three_season_porch  2930 non-null   int64  \n",
      " 61  Screen_Porch        2930 non-null   int64  \n",
      " 62  Pool_Area           2930 non-null   int64  \n",
      " 63  Pool_QC             2930 non-null   object \n",
      " 64  Fence               2930 non-null   object \n",
      " 65  Misc_Feature        106 non-null    object \n",
      " 66  Misc_Val            2930 non-null   int64  \n",
      " 67  Mo_Sold             2930 non-null   int64  \n",
      " 68  Year_Sold           2930 non-null   int64  \n",
      " 69  Sale_Type           2930 non-null   object \n",
      " 70  Sale_Condition      2930 non-null   object \n",
      " 71  Sale_Price          2930 non-null   int64  \n",
      " 72  Longitude           2930 non-null   float64\n",
      " 73  Latitude            2930 non-null   float64\n",
      "dtypes: float64(2), int64(32), object(40)\n",
      "memory usage: 1.7+ MB\n",
      "None\n",
      "##################################################\n",
      "The number of total rows   2930 \n",
      "The number of total variables  74 \n",
      "The variables names ['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] \n",
      "The qualitative variables ['MS_SubClass', 'MS_Zoning', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'Functional', 'Garage_Type', 'Garage_Finish', 'Garage_Cond', 'Paved_Drive', 'Pool_QC', 'Fence', 'Misc_Feature', 'Sale_Type', 'Sale_Condition'] \n",
      "The quantitative variables ['Lot_Frontage', 'Lot_Area', 'Year_Built', 'Year_Remod_Add', 'Mas_Vnr_Area', 'BsmtFin_SF_1', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Fireplaces', 'Garage_Cars', 'Garage_Area', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Price', 'Longitude', 'Latitude'] \n",
      "##################################################\n",
      "Total number missing value MS_SubClass       0\n",
      "MS_Zoning         0\n",
      "Lot_Frontage      0\n",
      "Lot_Area          0\n",
      "Street            0\n",
      "                 ..\n",
      "Sale_Type         0\n",
      "Sale_Condition    0\n",
      "Sale_Price        0\n",
      "Longitude         0\n",
      "Latitude          0\n",
      "Length: 74, dtype: int64 \n"
     ]
    }
   ],
   "source": [
    "def data_diagnostic(df):\n",
    "        print(\"#\"*50)\n",
    "        print(df.info())\n",
    "        print(\"#\"*50)\n",
    "        print(\"The number of total rows  {x: .0f} \".format(x=df.shape[0]))\n",
    "        print(\"The number of total variables {x: .0f} \".format(x=df.shape[1]))\n",
    "        print(\"The variables names {x:} \".format(x=list(df.columns.values)))\n",
    "\n",
    "        column_headers =list(df.columns.values)\n",
    "        qualitative_columns = [col for col in column_headers if df[col].dtype==\"object\"]\n",
    "        quantitative_columns = [col for col in column_headers if df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "        print(\"The qualitative variables {x:} \".format(x=qualitative_columns))\n",
    "        print(\"The quantitative variables {x:} \".format(x=quantitative_columns))\n",
    "        print(\"#\"*50)\n",
    "        print(\"Total number missing value {x:} \".format(x=df.isnull().sum()))\n",
    "data_diagnostic(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs in df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Misc_Feature    2824\n",
       "Mas_Vnr_Type    1775\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def na(df, percent = True):\n",
    "    srs = df.isna().sum()[df.isna().sum() > 0]\n",
    "    srs = srs.sort_values(ascending=False)\n",
    "    if percent:\n",
    "        print('% of NaNs in df:')\n",
    "        return srs / df.shape[0]\n",
    "    else:\n",
    "        print('# of NaNs in df:')\n",
    "        return srs\n",
    "\n",
    "na(df, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingDataHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df  # Appliquer les changements directement sur le DataFrame original\n",
    "    # 1. Supprimer les colonnes avec trop de valeurs manquantes\n",
    "    def drop_column(self, threshold=0.5):\n",
    "        \"\"\"Drop columns with more than threshold% missing values.\"\"\"\n",
    "        self.df.dropna(thresh=len(self.df) * (1 - threshold), axis=1, inplace=True)\n",
    "    # 2. Supprimer les lignes avec des valeurs manquantes\n",
    "    def drop_row(self):\n",
    "        \"\"\"Drop rows with any missing values.\"\"\"\n",
    "        self.df.dropna(inplace=True)\n",
    "    # 3. Imputation avec la moyenne ou la mÃ©diane\n",
    "    def impute_mean_median(self, strategy='mean'):\n",
    "        \"\"\"Impute missing values in all numerical columns with mean or median.\"\"\"\n",
    "        num_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        for col in num_cols:\n",
    "            imputer = SimpleImputer(strategy=strategy)\n",
    "            self.df[col] = imputer.fit_transform(self.df[[col]])\n",
    "    \n",
    "    def group_imputation(self, group_by, strategy='mean'):\n",
    "        \"\"\"Group-wise imputation using mean or median for all numerical columns.\"\"\"\n",
    "        num_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        for col in num_cols:\n",
    "            self.df[col].fillna(self.df.groupby(group_by)[col].transform(strategy), inplace=True)\n",
    "    # 4. Remplir par la valeur la plus frÃ©quente (catÃ©gories)\n",
    "    def impute_categorical(self, strategy='most_frequent', fill_value=None):\n",
    "        \"\"\"Impute missing values in all categorical columns.\"\"\"\n",
    "        cat_cols = self.df.select_dtypes(exclude=[np.number]).columns\n",
    "        for col in cat_cols:\n",
    "            if strategy == 'constant' and fill_value is not None:\n",
    "                self.df[col].fillna(fill_value, inplace=True)\n",
    "            else:\n",
    "                imputer = SimpleImputer(strategy=strategy)\n",
    "                self.df[col] = imputer.fit_transform(self.df[[col]]).ravel()\n",
    "    # 5. Remplissage en avant et en arriÃ¨re\n",
    "    def forward_fill(self):\n",
    "        \"\"\"Forward fill missing values for all columns.\"\"\"\n",
    "        self.df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    def backward_fill(self):\n",
    "        \"\"\"Backward fill missing values for all columns.\"\"\"\n",
    "        self.df.fillna(method='bfill', inplace=True)\n",
    "    # 6. Interpolation (utile pour les sÃ©ries temporelles)\n",
    "    def interpolate(self, method='linear'):\n",
    "        \"\"\"Interpolate missing values for all numerical columns.\"\"\"\n",
    "        num_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        for col in num_cols:\n",
    "            self.df[col].interpolate(method=method, inplace=True)\n",
    "    # using KNN for all numerical columns\n",
    "    def knn_imputation(self, n_neighbors=5):\n",
    "        \"\"\"Impute missing values using KNN for all numerical columns.\"\"\"\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        self.df[:] = imputer.fit_transform(self.df)\n",
    "    # using Iterative Imputer (MICE)\n",
    "    def iterative_imputation(self):\n",
    "        \"\"\"Impute missing values using Iterative Imputer (MICE) for all numerical columns.\"\"\"\n",
    "        imputer = IterativeImputer()\n",
    "        self.df[:] = imputer.fit_transform(self.df)\n",
    "    \n",
    "    def get_dataframe(self):\n",
    "        \"\"\"Return the processed DataFrame.\"\"\"\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame aprÃ¨s traitement :\n",
      "                              MS_SubClass                 MS_Zoning  \\\n",
      "0     One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
      "1     One_Story_1946_and_Newer_All_Styles  Residential_High_Density   \n",
      "2     One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
      "3     One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
      "4                Two_Story_1946_and_Newer   Residential_Low_Density   \n",
      "...                                   ...                       ...   \n",
      "2925                  Split_or_Multilevel   Residential_Low_Density   \n",
      "2926  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
      "2927                          Split_Foyer   Residential_Low_Density   \n",
      "2928  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
      "2929             Two_Story_1946_and_Newer   Residential_Low_Density   \n",
      "\n",
      "      Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n",
      "0            141.0   31770.0   Pave  No_Alley_Access  Slightly_Irregular   \n",
      "1             80.0   11622.0   Pave  No_Alley_Access             Regular   \n",
      "2             81.0   14267.0   Pave  No_Alley_Access  Slightly_Irregular   \n",
      "3             93.0   11160.0   Pave  No_Alley_Access             Regular   \n",
      "4             74.0   13830.0   Pave  No_Alley_Access  Slightly_Irregular   \n",
      "...            ...       ...    ...              ...                 ...   \n",
      "2925          37.0    7937.0   Pave  No_Alley_Access  Slightly_Irregular   \n",
      "2926           0.0    8885.0   Pave  No_Alley_Access  Slightly_Irregular   \n",
      "2927          62.0   10441.0   Pave  No_Alley_Access             Regular   \n",
      "2928          77.0   10010.0   Pave  No_Alley_Access             Regular   \n",
      "2929          74.0    9627.0   Pave  No_Alley_Access             Regular   \n",
      "\n",
      "     Land_Contour Utilities Lot_Config  ...  Pool_QC            Fence  \\\n",
      "0             Lvl    AllPub     Corner  ...  No_Pool         No_Fence   \n",
      "1             Lvl    AllPub     Inside  ...  No_Pool  Minimum_Privacy   \n",
      "2             Lvl    AllPub     Corner  ...  No_Pool         No_Fence   \n",
      "3             Lvl    AllPub     Corner  ...  No_Pool         No_Fence   \n",
      "4             Lvl    AllPub     Inside  ...  No_Pool  Minimum_Privacy   \n",
      "...           ...       ...        ...  ...      ...              ...   \n",
      "2925          Lvl    AllPub    CulDSac  ...  No_Pool     Good_Privacy   \n",
      "2926          Low    AllPub     Inside  ...  No_Pool  Minimum_Privacy   \n",
      "2927          Lvl    AllPub     Inside  ...  No_Pool  Minimum_Privacy   \n",
      "2928          Lvl    AllPub     Inside  ...  No_Pool         No_Fence   \n",
      "2929          Lvl    AllPub     Inside  ...  No_Pool         No_Fence   \n",
      "\n",
      "     Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition  Sale_Price  \\\n",
      "0         0.0     5.0    2010.0       WD          Normal    215000.0   \n",
      "1         0.0     6.0    2010.0       WD          Normal    105000.0   \n",
      "2     12500.0     6.0    2010.0       WD          Normal    172000.0   \n",
      "3         0.0     4.0    2010.0       WD          Normal    244000.0   \n",
      "4         0.0     3.0    2010.0       WD          Normal    189900.0   \n",
      "...       ...     ...       ...       ...            ...         ...   \n",
      "2925      0.0     3.0    2006.0       WD          Normal    142500.0   \n",
      "2926      0.0     6.0    2006.0       WD          Normal    131000.0   \n",
      "2927    700.0     7.0    2006.0       WD          Normal    132000.0   \n",
      "2928      0.0     4.0    2006.0       WD          Normal    170000.0   \n",
      "2929      0.0    11.0    2006.0       WD          Normal    188000.0   \n",
      "\n",
      "      Longitude   Latitude  \n",
      "0    -93.619754  42.054035  \n",
      "1    -93.619756  42.053014  \n",
      "2    -93.619387  42.052659  \n",
      "3    -93.617320  42.051245  \n",
      "4    -93.638933  42.060899  \n",
      "...         ...        ...  \n",
      "2925 -93.604776  41.988964  \n",
      "2926 -93.602680  41.988314  \n",
      "2927 -93.606847  41.986510  \n",
      "2928 -93.600190  41.990921  \n",
      "2929 -93.599996  41.989265  \n",
      "\n",
      "[2930 rows x 72 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Client\\AppData\\Local\\Temp\\ipykernel_7236\\2934517159.py:38: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  self.df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Importer la classe\n",
    "handler = MissingDataHandler(df)\n",
    "\n",
    "# Supprimer les colonnes avec plus de 50% de valeurs manquantes\n",
    "handler.drop_column(threshold=0.5)\n",
    "\n",
    "# Imputation des valeurs manquantes\n",
    "handler.impute_mean_median(strategy='median')  # Impute par la moyenne pour les colonnes numÃ©riques\n",
    "handler.impute_categorical(strategy='most_frequent')  # Impute par la valeur la plus frÃ©quente pour les catÃ©goriques\n",
    "\n",
    "# Utiliser forward fill ou backward fill si nÃ©cessaire\n",
    "handler.forward_fill()\n",
    "\n",
    "# RÃ©cupÃ©rer le DataFrame traitÃ©\n",
    "cleaned_df = handler.get_dataframe()\n",
    "\n",
    "print(\"\\nDataFrame aprÃ¨s traitement :\")\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NaNs in df:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def na(df, percent = True):\n",
    "    srs = df.isna().sum()[df.isna().sum() > 0]\n",
    "    srs = srs.sort_values(ascending=False)\n",
    "    if percent:\n",
    "        print('% of NaNs in df:')\n",
    "        return srs / df.shape[0]\n",
    "    else:\n",
    "        print('# of NaNs in df:')\n",
    "        return srs\n",
    "\n",
    "na(df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicates rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df, subset=None, keep='first', inplace=False):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from the DataFrame and provides a summary of duplicates.\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame from which to remove duplicates.\n",
    "        subset (list): List of columns to consider for duplicate checking. \n",
    "                    If None, checks all columns.\n",
    "        keep (str): Which duplicates to keep. Options:\n",
    "            - 'first': Keep the first occurrence (default).\n",
    "            - 'last': Keep the last occurrence.\n",
    "            - 'none': Drop all duplicates.\n",
    "        inplace (bool): If True, modifies the original DataFrame. \n",
    "                        If False, returns a new DataFrame.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed (if inplace=False).\n",
    "    \"\"\"\n",
    "    if keep not in ['first', 'last', 'none']:\n",
    "        raise ValueError(\"keep must be one of 'first', 'last', or 'none'.\")\n",
    "    # Count duplicates before removal\n",
    "    total_rows = len(df)\n",
    "    duplicate_rows = df.duplicated(subset=subset, keep=False).sum()\n",
    "    percentage_duplicates = (duplicate_rows / total_rows) * 100\n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "    print(f\"Duplicate Rows: {duplicate_rows} ({percentage_duplicates:.2f}%)\")\n",
    "    if duplicate_rows == 0:\n",
    "        print(\"No duplicates found. No rows removed.\")\n",
    "        return df if not inplace else None\n",
    "    # Handle duplicate removal    if keep == 'none':\n",
    "        # Drop all duplicates and keep only unique rows\n",
    "        duplicated_mask = df.duplicated(subset=subset, keep=False)\n",
    "        result = df[~duplicated_mask]\n",
    "    else:\n",
    "        # Use pandas built-in drop_duplicates\n",
    "        result = df.drop_duplicates(subset=subset, keep=keep)\n",
    "    # Count duplicates after removal\n",
    "    remaining_rows = len(result)\n",
    "    rows_removed = total_rows - remaining_rows\n",
    "    print(f\"Rows Removed: {rows_removed}\")\n",
    "    print(f\"Remaining Rows: {remaining_rows}\")\n",
    "    if rows_removed > 0:\n",
    "        print(\"Duplicates successfully removed.\")\n",
    "    else:\n",
    "        print(\"No duplicates were removed.\")\n",
    "    if inplace:\n",
    "        df.drop_duplicates(subset=subset, keep=keep, inplace=True)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 2930\n",
      "Duplicate Rows: 0 (0.00%)\n",
      "No duplicates found. No rows removed.\n"
     ]
    }
   ],
   "source": [
    "dm=remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, numerical_columns=None, method='IQR', verbose=True):\n",
    "    \"\"\"\n",
    "    Handles outliers in continuous numerical variables using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        numerical_columns (list): List of numerical columns to check for outliers. If None, auto-selects all numerical columns.\n",
    "        method (str): Method to handle outliers ('IQR' or 'Z-Score'). Default is 'IQR'.\n",
    "        verbose (bool): If True, displays outlier statistics.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers handled.\n",
    "    \"\"\"\n",
    "    # Select numerical columns if not provided\n",
    "    if numerical_columns is None:\n",
    "        numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    # Iterate over each numerical column\n",
    "    for col in numerical_columns:\n",
    "        if col in df.columns:\n",
    "            if method == 'IQR':\n",
    "                # Calculate Q1, Q3, and IQR\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                # Count and handle outliers\n",
    "                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound))\n",
    "                num_outliers = outliers.sum()\n",
    "                \n",
    "                # Option 1: Capping\n",
    "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"[INFO] Outliers handled in '{col}' using IQR:\")\n",
    "                    print(f\"         - Number of Outliers: {num_outliers}\")\n",
    "                    print(f\"         - Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "            elif method == 'Z-Score':\n",
    "                # Alternative method (if needed)\n",
    "                mean = df[col].mean()\n",
    "                std_dev = df[col].std()\n",
    "                threshold = 3  # Standard deviation threshold\n",
    "                \n",
    "                # Count and handle outliers\n",
    "                outliers = ((df[col] < (mean - threshold * std_dev)) | (df[col] > (mean + threshold * std_dev)))\n",
    "                num_outliers = outliers.sum()\n",
    "                \n",
    "                # Option 1: Capping\n",
    "                lower_bound = mean - threshold * std_dev\n",
    "                upper_bound = mean + threshold * std_dev\n",
    "                df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "                df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"[INFO] Outliers handled in '{col}' using Z-Score:\")\n",
    "                    print(f\"         - Number of Outliers: {num_outliers}\")\n",
    "                    print(f\"         - Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Outliers handled in 'Lot_Frontage' using IQR:\n",
      "         - Number of Outliers: 31\n",
      "         - Lower Bound: -9.5, Upper Bound: 130.5\n",
      "[INFO] Outliers handled in 'Lot_Area' using IQR:\n",
      "         - Number of Outliers: 127\n",
      "         - Lower Bound: 1267.75, Upper Bound: 17727.75\n",
      "[INFO] Outliers handled in 'Year_Built' using IQR:\n",
      "         - Number of Outliers: 9\n",
      "         - Lower Bound: 1883.5, Upper Bound: 2071.5\n",
      "[INFO] Outliers handled in 'Year_Remod_Add' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: 1906.5, Upper Bound: 2062.5\n",
      "[INFO] Outliers handled in 'Mas_Vnr_Area' using IQR:\n",
      "         - Number of Outliers: 203\n",
      "         - Lower Bound: -244.125, Upper Bound: 406.875\n",
      "[INFO] Outliers handled in 'BsmtFin_SF_1' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -3.0, Upper Bound: 13.0\n",
      "[INFO] Outliers handled in 'BsmtFin_SF_2' using IQR:\n",
      "         - Number of Outliers: 351\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Bsmt_Unf_SF' using IQR:\n",
      "         - Number of Outliers: 56\n",
      "         - Lower Bound: -655.125, Upper Bound: 1675.875\n",
      "[INFO] Outliers handled in 'Total_Bsmt_SF' using IQR:\n",
      "         - Number of Outliers: 124\n",
      "         - Lower Bound: 30.25, Upper Bound: 2064.25\n",
      "[INFO] Outliers handled in 'First_Flr_SF' using IQR:\n",
      "         - Number of Outliers: 43\n",
      "         - Lower Bound: 114.625, Upper Bound: 2145.625\n",
      "[INFO] Outliers handled in 'Second_Flr_SF' using IQR:\n",
      "         - Number of Outliers: 8\n",
      "         - Lower Bound: -1055.625, Upper Bound: 1759.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Outliers handled in 'Gr_Liv_Area' using IQR:\n",
      "         - Number of Outliers: 75\n",
      "         - Lower Bound: 200.875, Upper Bound: 2667.875\n",
      "[INFO] Outliers handled in 'Bsmt_Full_Bath' using IQR:\n",
      "         - Number of Outliers: 2\n",
      "         - Lower Bound: -1.5, Upper Bound: 2.5\n",
      "[INFO] Outliers handled in 'Bsmt_Half_Bath' using IQR:\n",
      "         - Number of Outliers: 175\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Full_Bath' using IQR:\n",
      "         - Number of Outliers: 4\n",
      "         - Lower Bound: -0.5, Upper Bound: 3.5\n",
      "[INFO] Outliers handled in 'Half_Bath' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -1.5, Upper Bound: 2.5\n",
      "[INFO] Outliers handled in 'Bedroom_AbvGr' using IQR:\n",
      "         - Number of Outliers: 78\n",
      "         - Lower Bound: 0.5, Upper Bound: 4.5\n",
      "[INFO] Outliers handled in 'Kitchen_AbvGr' using IQR:\n",
      "         - Number of Outliers: 134\n",
      "         - Lower Bound: 1.0, Upper Bound: 1.0\n",
      "[INFO] Outliers handled in 'TotRms_AbvGrd' using IQR:\n",
      "         - Number of Outliers: 51\n",
      "         - Lower Bound: 2.0, Upper Bound: 10.0\n",
      "[INFO] Outliers handled in 'Fireplaces' using IQR:\n",
      "         - Number of Outliers: 13\n",
      "         - Lower Bound: -1.5, Upper Bound: 2.5\n",
      "[INFO] Outliers handled in 'Garage_Cars' using IQR:\n",
      "         - Number of Outliers: 17\n",
      "         - Lower Bound: -0.5, Upper Bound: 3.5\n",
      "[INFO] Outliers handled in 'Garage_Area' using IQR:\n",
      "         - Number of Outliers: 42\n",
      "         - Lower Bound: -64.0, Upper Bound: 960.0\n",
      "[INFO] Outliers handled in 'Wood_Deck_SF' using IQR:\n",
      "         - Number of Outliers: 67\n",
      "         - Lower Bound: -252.0, Upper Bound: 420.0\n",
      "[INFO] Outliers handled in 'Open_Porch_SF' using IQR:\n",
      "         - Number of Outliers: 159\n",
      "         - Lower Bound: -105.0, Upper Bound: 175.0\n",
      "[INFO] Outliers handled in 'Enclosed_Porch' using IQR:\n",
      "         - Number of Outliers: 459\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Three_season_porch' using IQR:\n",
      "         - Number of Outliers: 37\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Screen_Porch' using IQR:\n",
      "         - Number of Outliers: 256\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Pool_Area' using IQR:\n",
      "         - Number of Outliers: 13\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Misc_Val' using IQR:\n",
      "         - Number of Outliers: 103\n",
      "         - Lower Bound: 0.0, Upper Bound: 0.0\n",
      "[INFO] Outliers handled in 'Mo_Sold' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -2.0, Upper Bound: 14.0\n",
      "[INFO] Outliers handled in 'Year_Sold' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: 2004.0, Upper Bound: 2012.0\n",
      "[INFO] Outliers handled in 'Sale_Price' using IQR:\n",
      "         - Number of Outliers: 137\n",
      "         - Lower Bound: 3500.0, Upper Bound: 339500.0\n",
      "[INFO] Outliers handled in 'Longitude' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: -93.71737362500002, Upper Bound: -93.56495702499998\n",
      "[INFO] Outliers handled in 'Latitude' using IQR:\n",
      "         - Number of Outliers: 0\n",
      "         - Lower Bound: 41.98044112499999, Upper Bound: 42.091500125\n"
     ]
    }
   ],
   "source": [
    "dc=handle_outliers(dm, numerical_columns=None, method='IQR', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 \n",
      " ['MS_SubClass', 'MS_Zoning', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'Functional', 'Garage_Type', 'Garage_Finish', 'Garage_Cond', 'Paved_Drive', 'Pool_QC', 'Fence', 'Sale_Type', 'Sale_Condition']\n"
     ]
    }
   ],
   "source": [
    "def get_object_columns(df):\n",
    "    \"\"\"\n",
    "    Cette fonction retourne la liste des colonnes de type 'object' dans un DataFrame.\n",
    "    \n",
    "    ParamÃ¨tres :\n",
    "    df (pd.DataFrame) : Le DataFrame Ã  analyser.\n",
    "    \n",
    "    Retour :\n",
    "    list : Liste des noms de colonnes de type 'object'.\n",
    "    \"\"\"\n",
    "    return df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# df = pd.read_csv('ton_fichier.csv')\n",
    "object_columns = get_object_columns(df)\n",
    "print(len(object_columns), \"\\n\", object_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(df, columns=object_columns, verbose=True):\n",
    "    \"\"\"\n",
    "    Performs Label Encoding on specified categorical columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to encode.\n",
    "        columns (list): List of column names to be label encoded.\n",
    "        verbose (bool): If True, displays the label mappings.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded columns.\n",
    "    \"\"\"\n",
    "    # Loop through the specified columns and encode them\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            \n",
    "            # Display label mapping\n",
    "            if verbose:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"\\n[INFO] Label Encoding for '{col}': {mapping}\")\n",
    "        else:\n",
    "            print(f\"[WARNING] Column '{col}' not found in DataFrame.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Label Encoding for 'MS_SubClass': {'Duplex_All_Styles_and_Ages': 0, 'One_Story_1945_and_Older': 1, 'One_Story_1946_and_Newer_All_Styles': 2, 'One_Story_PUD_1946_and_Newer': 3, 'One_Story_with_Finished_Attic_All_Ages': 4, 'One_and_Half_Story_Finished_All_Ages': 5, 'One_and_Half_Story_PUD_All_Ages': 6, 'One_and_Half_Story_Unfinished_All_Ages': 7, 'PUD_Multilevel_Split_Level_Foyer': 8, 'Split_Foyer': 9, 'Split_or_Multilevel': 10, 'Two_Family_conversion_All_Styles_and_Ages': 11, 'Two_Story_1945_and_Older': 12, 'Two_Story_1946_and_Newer': 13, 'Two_Story_PUD_1946_and_Newer': 14, 'Two_and_Half_Story_All_Ages': 15}\n",
      "\n",
      "[INFO] Label Encoding for 'MS_Zoning': {'A_agr': 0, 'C_all': 1, 'Floating_Village_Residential': 2, 'I_all': 3, 'Residential_High_Density': 4, 'Residential_Low_Density': 5, 'Residential_Medium_Density': 6}\n",
      "\n",
      "[INFO] Label Encoding for 'Street': {'Grvl': 0, 'Pave': 1}\n",
      "\n",
      "[INFO] Label Encoding for 'Alley': {'Gravel': 0, 'No_Alley_Access': 1, 'Paved': 2}\n",
      "\n",
      "[INFO] Label Encoding for 'Lot_Shape': {'Irregular': 0, 'Moderately_Irregular': 1, 'Regular': 2, 'Slightly_Irregular': 3}\n",
      "\n",
      "[INFO] Label Encoding for 'Land_Contour': {'Bnk': 0, 'HLS': 1, 'Low': 2, 'Lvl': 3}\n",
      "\n",
      "[INFO] Label Encoding for 'Utilities': {'AllPub': 0, 'NoSeWa': 1, 'NoSewr': 2}\n",
      "\n",
      "[INFO] Label Encoding for 'Lot_Config': {'Corner': 0, 'CulDSac': 1, 'FR2': 2, 'FR3': 3, 'Inside': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'Land_Slope': {'Gtl': 0, 'Mod': 1, 'Sev': 2}\n",
      "\n",
      "[INFO] Label Encoding for 'Neighborhood': {'Bloomington_Heights': 0, 'Blueste': 1, 'Briardale': 2, 'Brookside': 3, 'Clear_Creek': 4, 'College_Creek': 5, 'Crawford': 6, 'Edwards': 7, 'Gilbert': 8, 'Green_Hills': 9, 'Greens': 10, 'Iowa_DOT_and_Rail_Road': 11, 'Landmark': 12, 'Meadow_Village': 13, 'Mitchell': 14, 'North_Ames': 15, 'Northpark_Villa': 16, 'Northridge': 17, 'Northridge_Heights': 18, 'Northwest_Ames': 19, 'Old_Town': 20, 'Sawyer': 21, 'Sawyer_West': 22, 'Somerset': 23, 'South_and_West_of_Iowa_State_University': 24, 'Stone_Brook': 25, 'Timberland': 26, 'Veenker': 27}\n",
      "\n",
      "[INFO] Label Encoding for 'Condition_1': {'Artery': 0, 'Feedr': 1, 'Norm': 2, 'PosA': 3, 'PosN': 4, 'RRAe': 5, 'RRAn': 6, 'RRNe': 7, 'RRNn': 8}\n",
      "\n",
      "[INFO] Label Encoding for 'Condition_2': {'Artery': 0, 'Feedr': 1, 'Norm': 2, 'PosA': 3, 'PosN': 4, 'RRAe': 5, 'RRAn': 6, 'RRNn': 7}\n",
      "\n",
      "[INFO] Label Encoding for 'Bldg_Type': {'Duplex': 0, 'OneFam': 1, 'Twnhs': 2, 'TwnhsE': 3, 'TwoFmCon': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'House_Style': {'One_Story': 0, 'One_and_Half_Fin': 1, 'One_and_Half_Unf': 2, 'SFoyer': 3, 'SLvl': 4, 'Two_Story': 5, 'Two_and_Half_Fin': 6, 'Two_and_Half_Unf': 7}\n",
      "\n",
      "[INFO] Label Encoding for 'Overall_Cond': {'Above_Average': 0, 'Average': 1, 'Below_Average': 2, 'Excellent': 3, 'Fair': 4, 'Good': 5, 'Poor': 6, 'Very_Good': 7, 'Very_Poor': 8}\n",
      "\n",
      "[INFO] Label Encoding for 'Roof_Style': {'Flat': 0, 'Gable': 1, 'Gambrel': 2, 'Hip': 3, 'Mansard': 4, 'Shed': 5}\n",
      "\n",
      "[INFO] Label Encoding for 'Roof_Matl': {'ClyTile': 0, 'CompShg': 1, 'Membran': 2, 'Metal': 3, 'Roll': 4, 'Tar&Grv': 5, 'WdShake': 6, 'WdShngl': 7}\n",
      "\n",
      "[INFO] Label Encoding for 'Exterior_1st': {'AsbShng': 0, 'AsphShn': 1, 'BrkComm': 2, 'BrkFace': 3, 'CBlock': 4, 'CemntBd': 5, 'HdBoard': 6, 'ImStucc': 7, 'MetalSd': 8, 'Plywood': 9, 'PreCast': 10, 'Stone': 11, 'Stucco': 12, 'VinylSd': 13, 'Wd Sdng': 14, 'WdShing': 15}\n",
      "\n",
      "[INFO] Label Encoding for 'Exterior_2nd': {'AsbShng': 0, 'AsphShn': 1, 'Brk Cmn': 2, 'BrkFace': 3, 'CBlock': 4, 'CmentBd': 5, 'HdBoard': 6, 'ImStucc': 7, 'MetalSd': 8, 'Other': 9, 'Plywood': 10, 'PreCast': 11, 'Stone': 12, 'Stucco': 13, 'VinylSd': 14, 'Wd Sdng': 15, 'Wd Shng': 16}\n",
      "\n",
      "[INFO] Label Encoding for 'Exter_Cond': {'Excellent': 0, 'Fair': 1, 'Good': 2, 'Poor': 3, 'Typical': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'Foundation': {'BrkTil': 0, 'CBlock': 1, 'PConc': 2, 'Slab': 3, 'Stone': 4, 'Wood': 5}\n",
      "\n",
      "[INFO] Label Encoding for 'Bsmt_Cond': {'Excellent': 0, 'Fair': 1, 'Good': 2, 'No_Basement': 3, 'Poor': 4, 'Typical': 5}\n",
      "\n",
      "[INFO] Label Encoding for 'Bsmt_Exposure': {'Av': 0, 'Gd': 1, 'Mn': 2, 'No': 3, 'No_Basement': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'BsmtFin_Type_1': {'ALQ': 0, 'BLQ': 1, 'GLQ': 2, 'LwQ': 3, 'No_Basement': 4, 'Rec': 5, 'Unf': 6}\n",
      "\n",
      "[INFO] Label Encoding for 'BsmtFin_Type_2': {'ALQ': 0, 'BLQ': 1, 'GLQ': 2, 'LwQ': 3, 'No_Basement': 4, 'Rec': 5, 'Unf': 6}\n",
      "\n",
      "[INFO] Label Encoding for 'Heating': {'Floor': 0, 'GasA': 1, 'GasW': 2, 'Grav': 3, 'OthW': 4, 'Wall': 5}\n",
      "\n",
      "[INFO] Label Encoding for 'Heating_QC': {'Excellent': 0, 'Fair': 1, 'Good': 2, 'Poor': 3, 'Typical': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'Central_Air': {'N': 0, 'Y': 1}\n",
      "\n",
      "[INFO] Label Encoding for 'Electrical': {'FuseA': 0, 'FuseF': 1, 'FuseP': 2, 'Mix': 3, 'SBrkr': 4, 'Unknown': 5}\n",
      "\n",
      "[INFO] Label Encoding for 'Functional': {'Maj1': 0, 'Maj2': 1, 'Min1': 2, 'Min2': 3, 'Mod': 4, 'Sal': 5, 'Sev': 6, 'Typ': 7}\n",
      "\n",
      "[INFO] Label Encoding for 'Garage_Type': {'Attchd': 0, 'Basment': 1, 'BuiltIn': 2, 'CarPort': 3, 'Detchd': 4, 'More_Than_Two_Types': 5, 'No_Garage': 6}\n",
      "\n",
      "[INFO] Label Encoding for 'Garage_Finish': {'Fin': 0, 'No_Garage': 1, 'RFn': 2, 'Unf': 3}\n",
      "\n",
      "[INFO] Label Encoding for 'Garage_Cond': {'Excellent': 0, 'Fair': 1, 'Good': 2, 'No_Garage': 3, 'Poor': 4, 'Typical': 5}\n",
      "\n",
      "[INFO] Label Encoding for 'Paved_Drive': {'Dirt_Gravel': 0, 'Partial_Pavement': 1, 'Paved': 2}\n",
      "\n",
      "[INFO] Label Encoding for 'Pool_QC': {'Excellent': 0, 'Fair': 1, 'Good': 2, 'No_Pool': 3, 'Typical': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'Fence': {'Good_Privacy': 0, 'Good_Wood': 1, 'Minimum_Privacy': 2, 'Minimum_Wood_Wire': 3, 'No_Fence': 4}\n",
      "\n",
      "[INFO] Label Encoding for 'Sale_Type': {'COD': 0, 'CWD': 1, 'Con': 2, 'ConLD': 3, 'ConLI': 4, 'ConLw': 5, 'New': 6, 'Oth': 7, 'VWD': 8, 'WD ': 9}\n",
      "\n",
      "[INFO] Label Encoding for 'Sale_Condition': {'Abnorml': 0, 'AdjLand': 1, 'Alloca': 2, 'Family': 3, 'Normal': 4, 'Partial': 5}\n"
     ]
    }
   ],
   "source": [
    "dc=label_encode_columns(dc, columns=object_columns, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sales= dc[\"Sale_Price\"].mean()\n",
    "max_sales= dc[\"Sale_Price\"].max()\n",
    "min_sales= dc[\"Sale_Price\"].min()\n",
    "std_sales = dc[\"Sale_Price\"].std()\n",
    "dc[\"Mean_Sale_Price\"] = mean_sales\n",
    "dc[\"Max_Sale_Price\"] = max_sales\n",
    "dc[\"Min_Sale_Price\"] = min_sales\n",
    "dc[\"Std_Sale_Price\"] = std_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc[\"Total_Bathrooms\"] = dc[\"Bsmt_Full_Bath\"] + dc[\"Full_Bath\"] + 0.5 * (dc[\"Bsmt_Half_Bath\"] + dc[\"Half_Bath\"])\n",
    "dc[\"Total_Living_Area\"] = dc[\"Gr_Liv_Area\"] + dc[\"Total_Bsmt_SF\"]\n",
    "dc[\"Land_Living_Ratio\"] = dc[\"Lot_Area\"] / dc[\"Total_Living_Area\"]\n",
    "dc[\"Room_Density\"] = dc[\"Total_Living_Area\"] / dc[\"TotRms_AbvGrd\"]\n",
    "dc[\"Has_Garage\"] = dc[\"Garage_Area\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "dc[\"Garage_Size_Per_Car\"] = dc[\"Garage_Area\"] / (dc[\"Garage_Cars\"] + 1)\n",
    "dc[\"Total_Porch_Area\"] = dc[\"Wood_Deck_SF\"] + dc[\"Open_Porch_SF\"] + dc[\"Enclosed_Porch\"] + dc[\"Screen_Porch\"] + dc[\"Three_season_porch\"]\n",
    "expensive_neighborhoods = dc.groupby(\"Neighborhood\")[\"Sale_Price\"].median().sort_values(ascending=False).head(5).index\n",
    "dc[\"High_Value_Neighborhood\"] = dc[\"Neighborhood\"].apply(lambda x: 1 if x in expensive_neighborhoods else 0)\n",
    "dc[\"Has_Paved_Drive\"] = dc[\"Paved_Drive\"].map({\"Y\": 1, \"N\": 0})\n",
    "dc[\"Lot_Area_Log\"] = np.log1p(dc[\"Lot_Area\"])\n",
    "dc[\"Sale_Price_Log\"] = np.log1p(dc[\"Sale_Price\"])\n",
    "dc[\"Gr_Liv_Area_Log\"] = np.log1p(dc[\"Gr_Liv_Area\"])\n",
    "dc[\"House_Age\"] = dc[\"Year_Sold\"] - dc[\"Year_Built\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_price_sales= np.cos(dc[\"Sale_Price_Log\"])\n",
    "sin_price_sale= np.sin(dc[\"Sale_Price_Log\"])\n",
    "dc[\"cos_price_sales\"]=cos_price_sales\n",
    "dc[\"sin_price_sale\"]=sin_price_sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_used = [\n",
    "    \"Bsmt_Full_Bath\", \"Full_Bath\", \"Bsmt_Half_Bath\", \"Half_Bath\",  # UtilisÃ©s dans Total_Bathrooms\n",
    "    \"Gr_Liv_Area\", \"Total_Bsmt_SF\",  # UtilisÃ©s dans Total_Living_Area\n",
    "    \"Lot_Area\", \"Total_Living_Area\",  # UtilisÃ©s dans Land_Living_Ratio\n",
    "    \"Total_Living_Area\", \"TotRms_AbvGrd\",  # UtilisÃ©s dans Room_Density\n",
    "    \"Garage_Area\",  # UtilisÃ© dans Has_Garage et Garage_Size_Per_Car\n",
    "    \"Garage_Cars\",  # UtilisÃ© dans Garage_Size_Per_Car\n",
    "    \"Wood_Deck_SF\", \"Open_Porch_SF\", \"Enclosed_Porch\", \"Screen_Porch\", \"Three_season_porch\",  # UtilisÃ©s dans Total_Porch_Area\n",
    "    \"Neighborhood\",  # UtilisÃ© dans High_Value_Neighborhood\n",
    "    \"Paved_Drive\",  # UtilisÃ© dans Has_Paved_Drive\n",
    "    \"Lot_Area\",  # TransformÃ© avec Lot_Area_Log\n",
    "    \"Gr_Liv_Area\",  # TransformÃ© avec Gr_Liv_Area_Log\n",
    "    \"Year_Built\", \"Year_Sold\"  # UtilisÃ©s dans House_Age\n",
    "]\n",
    "cols_useless = ['Has_Paved_Drive'\n",
    "]\n",
    "cols_to_drop = cols_used + cols_useless\n",
    "dc.drop(columns=cols_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x= dc.drop(columns='Sale_Price_Log')\n",
    "y= dc['Sale_Price_Log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform only the selected columns\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test  = scaler.fit_transform(x_test)\n",
    "#x_t[columns_to_scale] = scaler.fit_transform(x_t[columns_to_scale])\n",
    "#x_te[columns_to_scale] = scaler.fit_transform(x_te[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MS_SubClass        0\n",
       "MS_Zoning          0\n",
       "Lot_Frontage       0\n",
       "Street             0\n",
       "Alley              0\n",
       "                  ..\n",
       "Sale_Price_Log     0\n",
       "Gr_Liv_Area_Log    0\n",
       "House_Age          0\n",
       "cos_price_sales    0\n",
       "sin_price_sale     0\n",
       "Length: 70, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Timing the training process\n",
    "training_start = time.perf_counter()\n",
    "model = lr.fit(x_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "\n",
    "# Timing the prediction process\n",
    "prediction_start = time.perf_counter()\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "prediction_end = time.perf_counter()\n",
    "\n",
    "# Calculate KPIs\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test , y_pred_test)\n",
    "\n",
    "# R-squared score\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Time metrics\n",
    "train_time = training_end - training_start\n",
    "prediction_time = prediction_end - prediction_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Performance:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0030\n",
      "  - MAE: 0.0020\n",
      "  - R^2 Score: 0.9999\n",
      "  - Training Time: 1.0843 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 0.0571\n",
      "  - MAE: 0.0219\n",
      "  - R^2 Score: 0.9810\n",
      "  - Prediction Time: 0.00565 seconds\n"
     ]
    }
   ],
   "source": [
    "# Output metrics\n",
    "print(\"Linear Regression Model Performance:\")\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "print(f\"  - MAE: {mae_train:.4f}\")\n",
    "print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "print(f\"  - MAE: {mae_test:.4f}\")\n",
    "print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162842.63499267888\n",
      "1.5135427826952261\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(y_test.mean()))\n",
    "print(np.exp(y_test.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Define models and parameter grids for GridSearchCV\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100,200,300,400,500]}\n",
    "ridge_grid = GridSearchCV(estimator=ridge, param_grid=ridge_params, \n",
    "                        cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# Lasso Regression Hypertuning\n",
    "lasso_grid = GridSearchCV(estimator=lasso, param_grid=lasso_params, \n",
    "                        cv=5, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge and Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Ridge Model: {'alpha': 0.01}\n",
      "\n",
      "Best Lasso Model: {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "ridge_grid.fit(x_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "print(\"\\nBest Ridge Model:\", ridge_grid.best_params_)\n",
    "\n",
    "\n",
    "lasso_grid.fit(x_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "print(\"\\nBest Lasso Model:\", lasso_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Ridge Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0030\n",
      "  - MAE: 0.0020\n",
      "  - R^2 Score: 0.9999\n",
      "  - Training Time: 0.0067 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 0.0571\n",
      "  - MAE: 0.0219\n",
      "  - R^2 Score: 0.9810\n",
      "  - Prediction Time: 0.00139 seconds\n",
      "\n",
      "Evaluating Lasso Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0110\n",
      "  - MAE: 0.0085\n",
      "  - R^2 Score: 0.9992\n",
      "  - Training Time: 0.0475 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 0.0679\n",
      "  - MAE: 0.0293\n",
      "  - R^2 Score: 0.9731\n",
      "  - Prediction Time: 0.00181 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best models\n",
    "best_models = {'Ridge': best_ridge, 'Lasso': best_lasso}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} Model:\")\n",
    "\n",
    "    # Timing the training process\n",
    "    training_start = time.perf_counter()\n",
    "    model.fit(x_train, y_train)\n",
    "    training_end = time.perf_counter()\n",
    "    \n",
    "    # Timing the prediction process\n",
    "    prediction_start = time.perf_counter()\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    prediction_end = time.perf_counter()\n",
    "\n",
    "    # Calculate KPIs\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    # Time metrics\n",
    "    train_time = training_end - training_start\n",
    "    prediction_time = prediction_end - prediction_start\n",
    "    # Output metrics\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"  - MAE: {mae_train:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "    print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "    print(\"\\nTesting Set:\")\n",
    "    print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"  - MAE: {mae_test:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "    print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modele ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finition et entraÃ®nement du modÃ¨le ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# DÃ©finir les hyperparamÃ¨tres Ã  tester\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 10.0],  # Force de rÃ©gularisation\n",
    "    'l1_ratio': [0.2, 0.5, 0.8]  # Ã‰quilibre entre L1 (Lasso) et L2 (Ridge)\n",
    "}\n",
    "\n",
    "elasticnet = ElasticNet()\n",
    "grid_search = GridSearchCV(elasticnet, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Meilleur modÃ¨le aprÃ¨s validation croisÃ©e\n",
    "best_elasticnet = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Ridge Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0030\n",
      "  - MAE: 0.0020\n",
      "  - R^2 Score: 0.9999\n",
      "  - Training Time: 0.0791 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 0.0571\n",
      "  - MAE: 0.0219\n",
      "  - R^2 Score: 0.9810\n",
      "  - Prediction Time: 0.00552 seconds\n",
      "\n",
      "Evaluating Lasso Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0110\n",
      "  - MAE: 0.0085\n",
      "  - R^2 Score: 0.9992\n",
      "  - Training Time: 0.0306 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 0.0679\n",
      "  - MAE: 0.0293\n",
      "  - R^2 Score: 0.9731\n",
      "  - Prediction Time: 0.00113 seconds\n",
      "\n",
      "Evaluating ElasticNet Model:\n",
      "\n",
      "Training Set:\n",
      "  - RMSE: 0.0330\n",
      "  - MAE: 0.0220\n",
      "  - R^2 Score: 0.9925\n",
      "  - Training Time: 0.0083 seconds\n",
      "\n",
      "Testing Set:\n",
      "  - RMSE: 0.1046\n",
      "  - MAE: 0.0418\n",
      "  - R^2 Score: 0.9362\n",
      "  - Prediction Time: 0.00136 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Meilleurs modÃ¨les aprÃ¨s validation croisÃ©e\n",
    "best_models = {'Ridge': best_ridge, 'Lasso': best_lasso, 'ElasticNet': best_elasticnet}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name} Model:\")\n",
    "\n",
    "    # Timing the training process\n",
    "    training_start = time.perf_counter()\n",
    "    model.fit(x_train, y_train)\n",
    "    training_end = time.perf_counter()\n",
    "    \n",
    "    # Timing the prediction process\n",
    "    prediction_start = time.perf_counter()\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    prediction_end = time.perf_counter()\n",
    "\n",
    "    # Calculate KPIs\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    # Time metrics\n",
    "    train_time = training_end - training_start\n",
    "    prediction_time = prediction_end - prediction_start\n",
    "    \n",
    "    # Output metrics\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  - RMSE: {rmse_train:.4f}\")\n",
    "    print(f\"  - MAE: {mae_train:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_train:.4f}\")\n",
    "    print(f\"  - Training Time: {train_time:.4f} seconds\")\n",
    "\n",
    "    print(\"\\nTesting Set:\")\n",
    "    print(f\"  - RMSE: {rmse_test:.4f}\")\n",
    "    print(f\"  - MAE: {mae_test:.4f}\")\n",
    "    print(f\"  - R^2 Score: {r2_test:.4f}\")\n",
    "    print(f\"  - Prediction Time: {prediction_time:.5f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
